from enum import Enum
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime


class EvidenceType(Enum):
    """ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã®ç¨®é¡"""
    WEB_SEARCH = "web_search"  # Webæ¤œç´¢çµæœ
    DOCUMENTATION = "documentation"  # æŠ€è¡“æ–‡æ›¸
    CODE_REFERENCE = "code_reference"  # ã‚³ãƒ¼ãƒ‰å‚ç…§
    ACADEMIC_PAPER = "academic_paper"  # å­¦è¡“è«–æ–‡
    OFFICIAL_DOCS = "official_docs"  # å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
    STACK_OVERFLOW = "stack_overflow"  # Stack Overflow
    GITHUB_ISSUE = "github_issue"  # GitHub Issue
    BLOG_POST = "blog_post"  # ãƒ–ãƒ­ã‚°è¨˜äº‹
    TUTORIAL = "tutorial"  # ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
    API_DOCS = "api_docs"  # APIæ–‡æ›¸


class CredibilityLevel(Enum):
    """ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«"""
    HIGH = "high"  # é«˜ä¿¡é ¼æ€§ï¼ˆå…¬å¼æ–‡æ›¸ã€å­¦è¡“è«–æ–‡ç­‰ï¼‰
    MEDIUM = "medium"  # ä¸­ä¿¡é ¼æ€§ï¼ˆæŠ€è¡“ãƒ–ãƒ­ã‚°ã€Stack Overflowç­‰ï¼‰
    LOW = "low"  # ä½ä¿¡é ¼æ€§ï¼ˆå€‹äººãƒ–ãƒ­ã‚°ã€æœªæ¤œè¨¼æƒ…å ±ç­‰ï¼‰


@dataclass
class Evidence:
    """ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æƒ…å ±"""
    title: str
    url: str
    content: str
    evidence_type: EvidenceType
    credibility: CredibilityLevel
    timestamp: datetime
    relevance_score: float  # é–¢é€£æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0.0-1.0ï¼‰
    source_domain: str
    tags: List[str]
    summary: Optional[str] = None


@dataclass
class EvidenceCollection:
    """ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³"""
    query: str
    evidences: List[Evidence]
    total_sources: int
    search_timestamp: datetime
    confidence_score: float  # å…¨ä½“ã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢


class EvidenceSystem:
    """ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æç¤ºã‚·ã‚¹ãƒ†ãƒ  - æ ¹æ‹ ã¨ãªã‚‹æƒ…å ±ã‚’åé›†ãƒ»æç¤º"""
    
    def __init__(self):
        self.credibility_weights = {
            CredibilityLevel.HIGH: 1.0,
            CredibilityLevel.MEDIUM: 0.7,
            CredibilityLevel.LOW: 0.4
        }
        
        self.domain_credibility = {
            # é«˜ä¿¡é ¼æ€§ãƒ‰ãƒ¡ã‚¤ãƒ³
            "docs.python.org": CredibilityLevel.HIGH,
            "developer.mozilla.org": CredibilityLevel.HIGH,
            "docs.microsoft.com": CredibilityLevel.HIGH,
            "kubernetes.io": CredibilityLevel.HIGH,
            "reactjs.org": CredibilityLevel.HIGH,
            "nodejs.org": CredibilityLevel.HIGH,
            "github.com": CredibilityLevel.HIGH,
            
            # ä¸­ä¿¡é ¼æ€§ãƒ‰ãƒ¡ã‚¤ãƒ³
            "stackoverflow.com": CredibilityLevel.MEDIUM,
            "medium.com": CredibilityLevel.MEDIUM,
            "dev.to": CredibilityLevel.MEDIUM,
            "qiita.com": CredibilityLevel.MEDIUM,
            "zenn.dev": CredibilityLevel.MEDIUM,
            
            # å­¦è¡“ç³»
            "arxiv.org": CredibilityLevel.HIGH,
            "ieee.org": CredibilityLevel.HIGH,
            "acm.org": CredibilityLevel.HIGH
        }
        
        self.evidence_templates = {
            "web_search": "ğŸ” Webæ¤œç´¢çµæœ",
            "documentation": "ğŸ“š æŠ€è¡“æ–‡æ›¸",
            "code_reference": "ğŸ’» ã‚³ãƒ¼ãƒ‰å‚ç…§",
            "academic_paper": "ğŸ“ å­¦è¡“è«–æ–‡",
            "official_docs": "ğŸ“‹ å…¬å¼æ–‡æ›¸",
            "stack_overflow": "â“ Stack Overflow",
            "github_issue": "ğŸ› GitHub Issue",
            "blog_post": "âœï¸ ãƒ–ãƒ­ã‚°è¨˜äº‹",
            "tutorial": "ğŸ¯ ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«",
            "api_docs": "âš™ï¸ APIæ–‡æ›¸"
        }
    
    async def gather_evidence(
            self,
            query: str,
            evidence_types: Optional[List[EvidenceType]] = None,
            max_results: int = 5
    ) -> EvidenceCollection:
        """æŒ‡å®šã•ã‚ŒãŸã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚’åé›†"""
        if evidence_types is None:
            evidence_types = [
                EvidenceType.WEB_SEARCH,
                EvidenceType.DOCUMENTATION,
                EvidenceType.STACK_OVERFLOW
            ]
        
        evidences = []
        
        for evidence_type in evidence_types:
            type_evidences = await self._search_by_type(
                query, evidence_type, max_results // len(evidence_types))
            evidences.extend(type_evidences)
        
        # é–¢é€£æ€§ã§ã‚½ãƒ¼ãƒˆ
        evidences.sort(key=lambda x: x.relevance_score, reverse=True)
        evidences = evidences[:max_results]
        
        # ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        confidence_score = self._calculate_confidence_score(evidences)
        
        return EvidenceCollection(
            query=query,
            evidences=evidences,
            total_sources=len(evidences),
            search_timestamp=datetime.now(),
            confidence_score=confidence_score
        )
    
    async def _search_by_type(self,
                              query: str,
                              evidence_type: EvidenceType,
                              max_results: int) -> List[Evidence]:
        """ã‚¿ã‚¤ãƒ—åˆ¥ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹æ¤œç´¢"""
        evidences = []
        
        if evidence_type == EvidenceType.WEB_SEARCH:
            evidences = await self._web_search(query, max_results)
        elif evidence_type == EvidenceType.DOCUMENTATION:
            evidences = await self._search_documentation(query, max_results)
        elif evidence_type == EvidenceType.STACK_OVERFLOW:
            evidences = await self._search_stackoverflow(query, max_results)
        elif evidence_type == EvidenceType.GITHUB_ISSUE:
            evidences = await self._search_github_issues(query, max_results)
        
        return evidences
    
    async def _web_search(self,
                          query: str,
                          max_results: int) -> List[Evidence]:
        """Webæ¤œç´¢ã‚’å®Ÿè¡Œ"""
        # Brave Search MCPã‚’ä½¿ç”¨
        try:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ run_mcp ã‚’ä½¿ç”¨
            search_results = await self._mock_brave_search(query, max_results)
            evidences = []
            
            for result in search_results:
                credibility = self._determine_credibility(result['url'])
                relevance = self._calculate_relevance(query, result['content'])
                
                evidence = Evidence(
                    title=result['title'],
                    url=result['url'],
                    content=result['content'],
                    evidence_type=EvidenceType.WEB_SEARCH,
                    credibility=credibility,
                    timestamp=datetime.now(),
                    relevance_score=relevance,
                    source_domain=self._extract_domain(
                        result['url']),
                    tags=self._extract_tags(result['content']),
                    summary=result.get('summary')
                )
                evidences.append(evidence)
            
            return evidences
        except Exception as e:
            print(f"Webæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def _search_documentation(self,
                                    query: str,
                                    max_results: int
                                    ) -> List[Evidence]:
        """æŠ€è¡“æ–‡æ›¸ã‚’æ¤œç´¢"""
        # Ref MCPã‚’ä½¿ç”¨
        try:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ run_mcp ã‚’ä½¿ç”¨
            doc_results = await self._mock_ref_search(query, max_results)
            evidences = []
            
            for result in doc_results:
                evidence = Evidence(
                    title=result['title'],
                    url=result['url'],
                    content=result['content'],
                    evidence_type=EvidenceType.DOCUMENTATION,
                    credibility=CredibilityLevel.HIGH,
                    timestamp=datetime.now(),
                    relevance_score=self._calculate_relevance(
                        query, result['content']),
                    source_domain=self._extract_domain(result['url']),
                    tags=self._extract_tags(result['content'])
                )
                evidences.append(evidence)
            
            return evidences
        except Exception as e:
            print(f"æ–‡æ›¸æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def _search_stackoverflow(self,
                                    query: str,
                                    max_results: int
                                    ) -> List[Evidence]:
        """Stack Overflowæ¤œç´¢"""
        # Stack Overflow APIã¾ãŸã¯Webæ¤œç´¢ã‚’ä½¿ç”¨
        try:
            # site:stackoverflow.com ã§Webæ¤œç´¢
            so_query = f"site:stackoverflow.com {query}"
            search_results = await self._mock_brave_search(
                so_query, max_results)
            evidences = []
            
            for result in search_results:
                evidence = Evidence(
                    title=result['title'],
                    url=result['url'],
                    content=result['content'],
                    evidence_type=EvidenceType.STACK_OVERFLOW,
                    credibility=CredibilityLevel.MEDIUM,
                    timestamp=datetime.now(),
                    relevance_score=self._calculate_relevance(
                        query, result['content']),
                    source_domain="stackoverflow.com",
                    tags=self._extract_tags(result['content'])
                )
                evidences.append(evidence)
            
            return evidences
        except Exception as e:
            print(f"Stack Overflowæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def _search_github_issues(self,
                                    query: str,
                                    max_results: int
                                    ) -> List[Evidence]:
        """GitHub Issuesæ¤œç´¢"""
        # GitHub MCPã‚’ä½¿ç”¨
        try:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ run_mcp ã‚’ä½¿ç”¨
            github_results = await self._mock_github_search(
                query, max_results)
            evidences = []
            
            for result in github_results:
                evidence = Evidence(
                    title=result['title'],
                    url=result['url'],
                    content=result['content'],
                    evidence_type=EvidenceType.GITHUB_ISSUE,
                    credibility=CredibilityLevel.MEDIUM,
                    timestamp=datetime.now(),
                    relevance_score=self._calculate_relevance(
                        query, result['content']),
                    source_domain="github.com",
                    tags=self._extract_tags(result['content'])
                )
                evidences.append(evidence)
            
            return evidences
        except Exception as e:
            print(f"GitHubæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _determine_credibility(self, url: str) -> CredibilityLevel:
        """URLã‹ã‚‰ä¿¡é ¼æ€§ã‚’åˆ¤å®š"""
        domain = self._extract_domain(url)
        return self.domain_credibility.get(domain, CredibilityLevel.LOW)
    
    def _extract_domain(self, url: str) -> str:
        """URLã‹ã‚‰ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’æŠ½å‡º"""
        import re
        match = re.search(r'https?://([^/]+)', url)
        if match:
            domain = match.group(1)
            # www. ã‚’é™¤å»
            if domain.startswith('www.'):
                domain = domain[4:]
            return domain
        return ""
    
    def _calculate_relevance(self, query: str, content: str) -> float:
        """é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        query_words = set(query.lower().split())
        content_words = set(content.lower().split())
        
        if not query_words:
            return 0.0
        
        # å˜ç´”ãªå˜èªãƒãƒƒãƒãƒ³ã‚°ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã‚ˆã‚Šé«˜åº¦ãªæ‰‹æ³•ã‚’ä½¿ç”¨ï¼‰
        matches = len(query_words.intersection(content_words))
        return min(matches / len(query_words), 1.0)
    
    def _extract_tags(self, content: str) -> List[str]:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ã‚¿ã‚°ã‚’æŠ½å‡º"""
        # æŠ€è¡“ç”¨èªã‚„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’æ¤œå‡º
        tech_terms = [
            'python', 'javascript', 'react', 'node.js', 'docker',
            'kubernetes', 'aws', 'azure', 'gcp', 'api', 'rest',
            'graphql', 'database', 'sql', 'nosql', 'mongodb',
            'postgresql', 'mysql', 'redis', 'nginx', 'apache'
        ]
        
        content_lower = content.lower()
        found_tags = []
        
        for term in tech_terms:
            if term in content_lower:
                found_tags.append(term)
        
        return found_tags[:5]  # æœ€å¤§5å€‹ã®ã‚¿ã‚°
    
    def _calculate_confidence_score(self,
                                    evidences: List[Evidence]) -> float:
        """å…¨ä½“ã®ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        if not evidences:
            return 0.0
        
        total_score = 0.0
        total_weight = 0.0
        
        for evidence in evidences:
            weight = self.credibility_weights[evidence.credibility]
            score = evidence.relevance_score * weight
            total_score += score
            total_weight += weight
        
        return total_score / total_weight if total_weight > 0 else 0.0
    
    def format_evidence_section(self,
                                collection: EvidenceCollection) -> str:
        """ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not collection.evidences:
            return ("\n\nğŸ“‹ **å‚è€ƒæƒ…å ±**\n"
                    "é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        
        section = (f"\n\nğŸ“‹ **å‚è€ƒæƒ…å ±** "
                   f"(ä¿¡é ¼æ€§: {collection.confidence_score:.1%})\n")
        
        for i, evidence in enumerate(collection.evidences, 1):
            icon = self.evidence_templates.get(
                evidence.evidence_type.value, "ğŸ“„")
            credibility_indicator = self._get_credibility_indicator(
                evidence.credibility)
            
            section += (f"{i}. {icon} **{evidence.title}** "
                        f"{credibility_indicator}\n")
            section += f"   ğŸ”— {evidence.url}\n"
            
            if evidence.summary:
                section += f"   ğŸ’¡ {evidence.summary}\n"
            
            if evidence.tags:
                tags_str = ", ".join(evidence.tags[:3])
                section += f"   ğŸ·ï¸ {tags_str}\n"
            
            section += "\n"
        
        return section
    
    def _get_credibility_indicator(self,
                                   credibility: CredibilityLevel) -> str:
        """ä¿¡é ¼æ€§ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã‚’å–å¾—"""
        indicators = {
            CredibilityLevel.HIGH: "ğŸŸ¢",
            CredibilityLevel.MEDIUM: "ğŸŸ¡",
            CredibilityLevel.LOW: "ğŸ”´"
        }
        return indicators.get(credibility, "âšª")
    
    # ãƒ¢ãƒƒã‚¯é–¢æ•°ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯å‰Šé™¤ï¼‰
    async def _mock_brave_search(self,
                                 query: str,
                                 max_results: int) -> List[Dict[str, str]]:
        """Brave Search ã®ãƒ¢ãƒƒã‚¯"""
        return [
            {
                "title": f"æ¤œç´¢çµæœ 1: {query}",
                "url": "https://example.com/result1",
                "content": f"ã“ã‚Œã¯{query}ã«é–¢ã™ã‚‹æƒ…å ±ã§ã™ã€‚",
                "summary": f"{query}ã®æ¦‚è¦èª¬æ˜"
            }
        ]
    
    async def _mock_ref_search(self,
                               query: str,
                               max_results: int) -> List[Dict[str, str]]:
        """Ref Search ã®ãƒ¢ãƒƒã‚¯"""
        return [
            {
                "title": f"æŠ€è¡“æ–‡æ›¸: {query}",
                "url": "https://docs.example.com/guide",
                "content": f"{query}ã®æŠ€è¡“çš„ãªèª¬æ˜ã§ã™ã€‚"
            }
        ]
    
    async def _mock_github_search(self,
                                  query: str,
                                  max_results: int) -> List[Dict[str, str]]:
        """GitHub Search ã®ãƒ¢ãƒƒã‚¯"""
        return [
            {
                "title": f"GitHub Issue: {query}",
                "url": "https://github.com/example/repo/issues/123",
                "content": f"{query}ã«é–¢ã™ã‚‹Issueã®å†…å®¹ã§ã™ã€‚"
            }
        ]